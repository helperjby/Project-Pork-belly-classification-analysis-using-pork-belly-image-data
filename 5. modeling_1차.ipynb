{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tqdm.keras import TqdmCallback\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'C:/Users/user/Downloads/data/pre_image'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training basic_cnn with size 120\n",
      "Found 12383 images belonging to 4 classes.\n",
      "Found 3093 images belonging to 4 classes.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 118, 118, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 59, 59, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 57, 57, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 28, 28, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 26, 26, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 13, 13, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 11, 11, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 5, 5, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6400)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               3277312   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 2052      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3667780 (13.99 MB)\n",
      "Trainable params: 3667780 (13.99 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a30d8a58e9184563b69d93696b8fbe24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "232700f0022e4658a335734a9a175fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0batch [00:00, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training basic_cnn with size 150\n",
      "Found 12383 images belonging to 4 classes.\n",
      "Found 3093 images belonging to 4 classes.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 74, 74, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 36, 36, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 17, 17, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 15, 15, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 7, 7, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 12544)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               6423040   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 2052      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6813508 (25.99 MB)\n",
      "Trainable params: 6813508 (25.99 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762c43c595674296b4d4c84c2a4efb17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ab917fa47b40609f8a7448600451c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0batch [00:00, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training vgg16 with size 120\n",
      "Found 12383 images belonging to 4 classes.\n",
      "Found 3093 images belonging to 4 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 2s 0us/step\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 3, 3, 512)         14714688  \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               2359808   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 2052      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17076548 (65.14 MB)\n",
      "Trainable params: 2361860 (9.01 MB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf0746718a84fd386a9ce9c51ceee4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eaea20d7f7b4ddd81b6cd924c95469b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0batch [00:00, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training vgg16 with size 150\n",
      "Found 12383 images belonging to 4 classes.\n",
      "Found 3093 images belonging to 4 classes.\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               4194816   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4)                 2052      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18911556 (72.14 MB)\n",
      "Trainable params: 4196868 (16.01 MB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb52b06f5db4fc7a64c7edd2e2432aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339512049a3142dca4cb58b7e7256884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0batch [00:00, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training resnet50 with size 224\n",
      "Found 12383 images belonging to 4 classes.\n",
      "Found 3093 images belonging to 4 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 4s 0us/step\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 100352)            0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 512)               51380736  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4)                 2052      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74970500 (285.99 MB)\n",
      "Trainable params: 51382788 (196.01 MB)\n",
      "Non-trainable params: 23587712 (89.98 MB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057ecd4f986a4f23a56d8f74b2bcf8f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b68e805cdfc4cb0897fff0910e760cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0batch [00:00, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 전처리\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "# 모델 구성 함수\n",
    "def build_model(model_name, input_size, num_classes=4):\n",
    "    if model_name == 'basic_cnn':\n",
    "        model = Sequential([\n",
    "            Conv2D(32, (3, 3), activation='relu', input_shape=(input_size, input_size, 3)),\n",
    "            MaxPooling2D(2, 2),\n",
    "            Conv2D(64, (3, 3), activation='relu'),\n",
    "            MaxPooling2D(2, 2),\n",
    "            Conv2D(128, (3, 3), activation='relu'),\n",
    "            MaxPooling2D(2, 2),\n",
    "            Conv2D(256, (3, 3), activation='relu'),  # Conv2D 256 필터 추가\n",
    "            MaxPooling2D(2, 2),\n",
    "            Flatten(),\n",
    "            Dense(512, activation='relu'),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "    elif model_name == 'vgg16':\n",
    "        base_model = VGG16(input_shape=(input_size, input_size, 3), include_top=False, weights='imagenet')\n",
    "        base_model.trainable = False\n",
    "        model = Sequential([\n",
    "            base_model,\n",
    "            Flatten(),\n",
    "            Dense(512, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "    elif model_name == 'resnet50': \n",
    "        base_model = ResNet50(input_shape=(input_size, input_size, 3), include_top=False, weights='imagenet')\n",
    "        base_model.trainable = False\n",
    "        model = Sequential([\n",
    "            base_model,\n",
    "            Flatten(),\n",
    "            Dense(512, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 모델, target size, batch size, epochs 설정\n",
    "models_info = [\n",
    "    ('basic_cnn', [120, 150]),  # target size 수정: 60 삭제, 150 추가\n",
    "    ('vgg16', [120, 150]),\n",
    "    ('resnet50', [224]),\n",
    "]\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "\n",
    "# Early stopping 콜백 설정\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3)  # 3회 이상 개선이 없으면 학습 중단\n",
    "\n",
    "# 성능 저장을 위한 딕셔너리\n",
    "performance_metrics = {}\n",
    "\n",
    "# 각 모델별로 훈련 및 성능 평가\n",
    "for model_info in models_info:\n",
    "    model_name, sizes = model_info\n",
    "    for size in sizes:\n",
    "        print(f\"Training {model_name} with size {size}\")\n",
    "\n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "            base_dir,\n",
    "            target_size=(size, size),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical',\n",
    "            subset='training')\n",
    "        \n",
    "        validation_generator = train_datagen.flow_from_directory(\n",
    "            base_dir,\n",
    "            target_size=(size, size),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical',\n",
    "            subset='validation')\n",
    "        \n",
    "        model = build_model(model_name, size)\n",
    "        model.summary()  # 모델 구조 출력\n",
    "\n",
    "        # 모델 학습\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            steps_per_epoch=train_generator.samples // batch_size,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=validation_generator.samples // batch_size,\n",
    "            epochs=epochs,\n",
    "            callbacks=[TqdmCallback(verbose=1), early_stop],  # EarlyStopping 콜백 추가\n",
    "            verbose=0  # tqdm을 사용하기 때문에 기본 출력은 끕니다.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training basic_cnn with size 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at saved_models\\basic_cnn_120.h5\n",
      "Training history saved at saved_models\\basic_cnn_120_history.json\n",
      "Training basic_cnn with size 150\n",
      "Model saved at saved_models\\basic_cnn_150.h5\n",
      "Training history saved at saved_models\\basic_cnn_150_history.json\n",
      "Training vgg16 with size 120\n",
      "Model saved at saved_models\\vgg16_120.h5\n",
      "Training history saved at saved_models\\vgg16_120_history.json\n",
      "Training vgg16 with size 150\n",
      "Model saved at saved_models\\vgg16_150.h5\n",
      "Training history saved at saved_models\\vgg16_150_history.json\n",
      "Training resnet50 with size 224\n",
      "Model saved at saved_models\\resnet50_224.h5\n",
      "Training history saved at saved_models\\resnet50_224_history.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# 모델 및 히스토리 저장 디렉토리 생성\n",
    "save_dir = \"saved_models\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# 각 모델별로 훈련 및 성능 평가\n",
    "for model_info in models_info:\n",
    "    model_name, sizes = model_info\n",
    "    for size in sizes:\n",
    "        print(f\"Training {model_name} with size {size}\")\n",
    "\n",
    "        # 모델 저장\n",
    "        model_save_path = os.path.join(save_dir, f\"{model_name}_{size}.h5\")\n",
    "        model.save(model_save_path)\n",
    "        print(f\"Model saved at {model_save_path}\")\n",
    "\n",
    "        # 히스토리 저장\n",
    "        history_dict = history.history\n",
    "        history_save_path = os.path.join(save_dir, f\"{model_name}_{size}_history.json\")\n",
    "        with open(history_save_path, 'w') as file:\n",
    "            json.dump(history_dict, file)\n",
    "        print(f\"Training history saved at {history_save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
